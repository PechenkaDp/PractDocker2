{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf552d5f-7027-4b6f-9556-647390dc1764",
   "metadata": {},
   "source": [
    "# Импорт библиотек и загрузка данных и предобработка данных для кластерного анализа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0090bac2-0178-491f-b45a-62a6bb33338f",
   "metadata": {},
   "source": [
    "### Здесь мы начинаем с импорта необходимых библиотек для работы с данными и кластерным анализом. Важно импортировать pandas для работы с данными в виде датафрейма, а также различные классы и функции из scikit-learn для предобработки данных, кластерного анализа и оценки метрик. Затем мы выбираем числовые признаки из исходного датасета, которые будем использовать для кластеризации. Это важно, так как большинство алгоритмов кластерного анализа работают только с числовыми данными. После выбора признаков мы выполняем стандартизацию данных с помощью StandardScaler. Это необходимо для того, чтобы признаки имели одинаковый масштаб и алгоритмы кластеризации работали корректно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5b5a48e-6c64-447b-8c2d-fba684e2bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "df = pd.read_csv('dataset_salary_2024_encoded.csv')\n",
    "\n",
    "numerical_features = ['work_year', 'salary_in_usd', 'remote_ratio', 'employment_type_encoded', 'company_location_encoded', 'salary_scaled', 'work_year_scaled', 'salary_minmax', 'work_year_minmax', 'salary_normalized', 'work_year_normalized', 'salary_robust_scaled', 'salary_transformed']\n",
    "\n",
    "X = df[numerical_features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb63403-1468-4389-bee8-76ed9163b4e1",
   "metadata": {},
   "source": [
    "# Обучение и оценка моделей кластерного анализа до понижения размерности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c069ef9-dca1-4dd4-a117-ae608fb6534c",
   "metadata": {},
   "source": [
    "### Здесь мы инициализируем две модели кластеризации: KMeans с 3 кластерами и AgglomerativeClustering с 3 кластерами. Эти модели выбраны для демонстрации различных подходов к кластеризации данных. Для оценки качества кластеризации мы используем три метрики: silhouette_score, davies_bouldin_score и calinski_harabasz_score. Эти метрики помогают понять, насколько хорошо данные кластеризуются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47fbbb69-14fd-4532-89b2-aa8568f4120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KMeans...\n",
      "Training AgglomerativeClustering...\n",
      "Metrics before PCA:\n",
      "\n",
      "KMeans:\n",
      "silhouette_score: 0.3162531261993673\n",
      "davies_bouldin_score: 1.2624629887868484\n",
      "calinski_harabasz_score: 3265.861432948947\n",
      "\n",
      "AgglomerativeClustering:\n",
      "silhouette_score: 0.2991950939997449\n",
      "davies_bouldin_score: 1.388139932959817\n",
      "calinski_harabasz_score: 2768.042791492936\n"
     ]
    }
   ],
   "source": [
    "clustering_models = {\n",
    "    'KMeans': KMeans(n_clusters=3, random_state=42),  \n",
    "    'AgglomerativeClustering': AgglomerativeClustering(n_clusters=3)  \n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    'silhouette_score': silhouette_score,\n",
    "    'davies_bouldin_score': davies_bouldin_score,\n",
    "    'calinski_harabasz_score': calinski_harabasz_score\n",
    "}\n",
    "\n",
    "def evaluate_clustering(models, X):\n",
    "    results = {}\n",
    "    for model_name, model in models.items():  \n",
    "        print(f\"Training {model_name}...\")  \n",
    "        labels = model.fit_predict(X) \n",
    "        \n",
    "        model_metrics = {}\n",
    "        for metric_name, metric_func in metrics.items():  \n",
    "            score = metric_func(X, labels)  \n",
    "            model_metrics[metric_name] = score  \n",
    "        \n",
    "        results[model_name] = model_metrics  \n",
    "    return results  \n",
    "\n",
    "results_before_pca = evaluate_clustering(clustering_models, X_scaled)\n",
    "\n",
    "print(\"Metrics before PCA:\")\n",
    "for model_name, model_metrics in results_before_pca.items():  \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric_name, score in model_metrics.items():  \n",
    "        print(f\"{metric_name}: {score}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d014f-e207-4e7c-985d-e40b12136a09",
   "metadata": {},
   "source": [
    "# Понижение размерности данных с помощью PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e104f6-b3d8-4d1e-b9bf-8ac648edac01",
   "metadata": {},
   "source": [
    "### Здесь мы применяем метод главных компонент (PCA) для уменьшения размерности данных до 2 компонентов. Это делается с целью улучшения работы некоторых алгоритмов кластеризации и визуализации результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd9098b-235f-4ee3-8862-6af0736e9bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa25acf9-17f0-49a8-b7a8-f8e61ca290fd",
   "metadata": {},
   "source": [
    "# Повторное обучение и оценка моделей кластерного анализа после понижения размерности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce662f61-933a-417d-a30f-a9bd01c1ca88",
   "metadata": {},
   "source": [
    "### После применения PCA мы повторно обучаем и оцениваем те же модели кластерного анализа (KMeans и AgglomerativeClustering) на данных с пониженной размерностью. Мы снова используем те же метрики для оценки качества кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b719c28d-bda2-4cff-84c6-9229176c58a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KMeans...\n",
      "Training AgglomerativeClustering...\n",
      "Metrics after PCA:\n",
      "\n",
      "KMeans:\n",
      "silhouette_score: 0.4338178902886084\n",
      "davies_bouldin_score: 0.932788661817627\n",
      "calinski_harabasz_score: 6082.9386900143\n",
      "\n",
      "AgglomerativeClustering:\n",
      "silhouette_score: 0.3854201059201704\n",
      "davies_bouldin_score: 0.9331730004724944\n",
      "calinski_harabasz_score: 5103.215450438755\n"
     ]
    }
   ],
   "source": [
    "results_after_pca = evaluate_clustering(clustering_models, X_pca)\n",
    "\n",
    "print(\"Metrics after PCA:\")\n",
    "for model_name, model_metrics in results_after_pca.items():  \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric_name, score in model_metrics.items():  \n",
    "        print(f\"{metric_name}: {score}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6e77a-5446-4bfa-9333-93c4f7bd6bc4",
   "metadata": {},
   "source": [
    "# Сравнение результатов и выбор наилучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d968ab3-351a-442d-bf18-d52d378b0acc",
   "metadata": {},
   "source": [
    "### В этом блоке мы сравниваем результаты кластеризации до и после применения PCA. Мы анализируем значения метрик (silhouette_score, davies_bouldin_score и calinski_harabasz_score) для каждой модели. Затем мы выбираем наилучшую модель на основе метрики silhouette_score, так как эта метрика дает представление о компактности кластеров и их разделимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4235ddd7-80ee-456a-b6f9-968332afce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of metrics before and after PCA:\n",
      "\n",
      "KMeans:\n",
      "silhouette_score: Before PCA = 0.3162531261993673, After PCA = 0.4338178902886084\n",
      "davies_bouldin_score: Before PCA = 1.2624629887868484, After PCA = 0.932788661817627\n",
      "calinski_harabasz_score: Before PCA = 3265.861432948947, After PCA = 6082.9386900143\n",
      "\n",
      "AgglomerativeClustering:\n",
      "silhouette_score: Before PCA = 0.2991950939997449, After PCA = 0.3854201059201704\n",
      "davies_bouldin_score: Before PCA = 1.388139932959817, After PCA = 0.9331730004724944\n",
      "calinski_harabasz_score: Before PCA = 2768.042791492936, After PCA = 5103.215450438755\n",
      "\n",
      "Best model before PCA: KMeans with silhouette_score = 0.3162531261993673\n",
      "Best model after PCA: KMeans with silhouette_score = 0.4338178902886084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nComparison of metrics before and after PCA:\")\n",
    "for model_name in results_before_pca.keys():  \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric_name in metrics.keys():  \n",
    "        score_before = results_before_pca[model_name][metric_name]  \n",
    "        score_after = results_after_pca[model_name][metric_name] \n",
    "        print(f\"{metric_name}: Before PCA = {score_before}, After PCA = {score_after}\")  \n",
    "\n",
    "best_model_name_before_pca = max(results_before_pca, key=lambda x: results_before_pca[x]['silhouette_score'])\n",
    "best_model_name_after_pca = max(results_after_pca, key=lambda x: results_after_pca[x]['silhouette_score'])\n",
    "\n",
    "print(f\"\\nBest model before PCA: {best_model_name_before_pca} with silhouette_score = {results_before_pca[best_model_name_before_pca]['silhouette_score']}\")\n",
    "print(f\"Best model after PCA: {best_model_name_after_pca} with silhouette_score = {results_after_pca[best_model_name_after_pca]['silhouette_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4355c-c832-4a85-bbbd-6a5c43fc36fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
